import tensorflow as tf
import numpy as np
import scipy.io
import pickle

def one_hot(x, n_classes=None):
    assert(np.array(x).ndim == 1)
    
    # input: 1D array of N labels, output: N x max(x)+1 array of one-hot vectors
    if n_classes is None:
        n_classes = max(x) + 1

    x_one_hot = np.zeros([len(x), n_classes])
    x_one_hot[np.arange(len(x)), x] = 1
    return x_one_hot


def load_mnist(n_data=None):
    (train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()

    # randomize order
    permutation = np.random.permutation(len(train_labels))
    train_data = train_data[permutation]
    train_labels = train_labels[permutation]
    permutation = np.random.permutation(len(test_labels))
    test_data = test_data[permutation]
    test_labels = test_labels[permutation]

    # normalize, reshape, and convert to one-hot vectors
    train_data = np.reshape(train_data, (-1, 784)) / (255./2.) - 1.
    test_data = np.reshape(test_data, (-1, 784)) / (255./2.) - 1.
    train_labels = one_hot(train_labels)
    test_labels = one_hot(test_labels)

    if n_data is not None:
        data = {'trn_X': train_data[:n_data], 'trn_Y': train_labels[:n_data], 
                'tst_X': test_data[:n_data] , 'tst_Y': test_labels[:n_data]}
    else:
        data = {'trn_X': train_data, 'trn_Y': train_labels, 
                'tst_X': test_data , 'tst_Y': test_labels}

    data['entropyY'] = np.log(10)
    return data

def load_wine():
    mx = np.vstack([
        np.genfromtxt('data/winequality-red.csv',delimiter=";", skip_header=1),
        np.genfromtxt('data/winequality-white.csv',delimiter=";", skip_header=1),
    ])
    np.random.seed(12345)
    permutation  = np.random.permutation(len(mx))
    mx = mx[permutation,:]

    X = mx[permutation,:-1]
    y = mx[permutation,-1]
    #Y = one_hot(y.astype('int')) # 
    Y = np.zeros( (len(mx), 2))
    Y[y < 6,0] = 1.0 
    Y[y >= 6,1] = 1.0 
    #Y[y == 5,:] = 0.5
    ps = Y.mean(axis=0)
    entropyY = np.sum([-p*np.log(p) for p in ps if not np.isclose(p,0)])
                      
    hl = int(len(mx)/2)

    data = { 'trn_X' : X[:hl,:], 'trn_Y': Y[:hl,:],
             'tst_X' : X[hl:,:], 'tst_Y': Y[hl:,:],
             'entropyY' : entropyY}
    
    return data

def load_szt():
    # Data from artificial dataset used in Schwartz-Ziv and Tishby
    d1 = scipy.io.loadmat('data/g1.mat')
    d2 = scipy.io.loadmat('data/g2.mat')
    data = { 'trn_X' : d1['F'].astype('float32'), 'trn_Y': trainutils.one_hot(d1['y'].flat),
             'tst_X' : d2['F'].astype('float32'), 'tst_Y': trainutils.one_hot(d2['y'].flat),
             'entropyY': np.log(2)}
    return data    

def load_data(runtype):
    if runtype == 'MNIST':
        data = load_mnist()
    elif runtype == 'NoisyClassifierWine':
        data = load_wine()
    elif runtype == 'NoisyClassifier':
        data = load_szt()
    elif runtype == 'Regression':
        # data generated by makeregressiondata.py
        with open('data/regression-100-10.pkl', 'rb') as f:
            data = pickle.load(f)
        labelcov = np.cov(data['trn_Y'].T)
        data['entropyY'] = 0.5 * np.log(np.linalg.det(2*np.pi*np.exp(1)*labelcov))
    else:
        raise Exception('unknown runtype')
    
    return data
    

