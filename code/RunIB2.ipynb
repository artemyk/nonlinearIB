{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import loaddata, iblayer, trainutils\n",
    "\n",
    "# Dictionary to \n",
    "cfg = {}\n",
    "cfg['squaredIB'] = True\n",
    "cfg['n_batch']   = 128\n",
    "cfg['n_epochs']  = 150\n",
    "cfg['n_noisevar_batch'] = 1000 \n",
    "cfg['report_every']  = 10\n",
    "\n",
    "betavals = 10**np.linspace(-5, 0.1, 30, endpoint=True)\n",
    "\n",
    "savedirbase  = str(pathlib.Path().absolute()) + '/saveddata-testthread/'\n",
    "savedir = savedirbase + 'MNIST'\n",
    "\n",
    "tfconfig = tf.ConfigProto()\n",
    "tfconfig.gpu_options.allow_growth=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim      = input_dim\n",
    "        self.output_dim     = output_dim\n",
    "        \n",
    "        \n",
    "        self.iblayerobj     = iblayer.NoisyIBLayer(n_noisevar_batch=cfg['n_noisevar_batch'], \n",
    "                                                   init_noisevar=0.01, init_kdewidth=-20)\n",
    "        \n",
    "        self.true_outputs   = tf.placeholder(tf.float32, [None,output_dim,], name='true_outputs')\n",
    "\n",
    "        # TODO: build the network\n",
    "        self.layers = []\n",
    "        self.layers.append( tf.placeholder(tf.float32, [None,input_dim,], name='X') ) # tf.keras.layers.Input([input_dim,])\n",
    "        self.layers.append( tf.keras.layers.Dense(512, activation=tf.nn.relu, name='encoder_0')(self.layers[-1]) )\n",
    "        self.layers.append( tf.keras.layers.Dense(512, activation=tf.nn.relu, name='encoder_1')(self.layers[-1]) )\n",
    "        self.layers.append( tf.keras.layers.Dense(2  , activation=None, name='encoder_2')(self.layers[-1]) )\n",
    "        \n",
    "        # tf.identity(self.layers[-1], name='T_nonoise')\n",
    "        # # makes it easy to identify this layer by name 'T_nonoise' later\n",
    "        \n",
    "        self.layers.append( self.iblayerobj(self.layers[-1]) )\n",
    "        self.layers.append( tf.keras.layers.Dense(512, activation=tf.nn.relu, name='decoder_0')(self.layers[-1]) )\n",
    "        self.layers.append( tf.keras.layers.Dense(output_dim, activation=None, name='decoder_1')(self.layers[-1]) )\n",
    "\n",
    "        self.inputs         = self.layers[0]\n",
    "        self.predictions    = self.layers[-1]\n",
    "\n",
    "        f                   = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.true_outputs, logits=self.predictions)\n",
    "        self.cross_entropy  = tf.reduce_mean(f) # cross entropy\n",
    "        self.accuracy       = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.predictions, 1), tf.argmax(self.true_outputs, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data           = loaddata.load_data('MNIST')\n",
    "input_dim      = data['trn_X'].shape[1]\n",
    "output_dim     = data['trn_Y'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making base model\n",
      "*** Saving to tbtest/ ***\n",
      "\n",
      "mode: ce epoch: 0 | beta: 0.0000 | noisevar: 0.01 | kw: 2.06115e-09 | time/epoch: -\n",
      "ce:  2.303/ 2.304 | acc:  0.125/ 0.120 | loss:  2.303/ 2.304 | \n",
      "Ixt:  3.360/ 3.410 | Ixt_lb:  2.043/ 2.090 | vIxt:  8.334/ 8.343 | Iyt: -0.000/-0.001 | \n",
      "Model saved in path: tbtest/\n"
     ]
    }
   ],
   "source": [
    "# Test reloading\n",
    "import os\n",
    "cur_dir = 'tbtest/' # savedir+'/test2'\n",
    "filelist = [ f for f in os.listdir(cur_dir)  if not f.startswith('.')]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(cur_dir, f))\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tfconfig) as sess:\n",
    "    print(\"Making base model\")\n",
    "    n = Network(input_dim, output_dim)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #print(n.iblayerobj.T_nonoise.name)\n",
    "    #print( sess.run('noisy_ib_layer/RawInput:0', feed_dict={'X:0':data['trn_X']}) )\n",
    "    #print( sess.run(n.iblayerobj.T_nonoise, feed_dict={'X:0':data['trn_X']}) )\n",
    "    file_writer = tf.summary.FileWriter(cur_dir, sess.graph)\n",
    "    #asdf\n",
    "    cfg2 = cfg.copy()\n",
    "    cfg2['n_epochs'] =0\n",
    "    trainutils.train(sess, mode='ce', beta=0.0, net=n, cfg=cfg2, \n",
    "                data=data, savedir=cur_dir)\n",
    "    print(\"Model saved in path: %s\" % cur_dir)\n",
    "    \n",
    "    #for n in tf.get_default_graph().as_graph_def().node:\n",
    "    #    if n.name.startswith('noisy_ib'):\n",
    "    #        print(n.name)\n",
    "    #print( sess.run('T_nonoise', feed_dict={'X:0':data['trn_X']}) )\n",
    "    #print( sess.run('T_nonoise', feed_dict={'X:0':data['trn_X']}) )\n",
    "    \n",
    "    # print( sess.run(tf.identity(n.layers[3]), feed_dict={'X:0':data['trn_X']}) )\n",
    "    \n",
    "    file_writer = tf.summary.FileWriter(cur_dir, sess.graph)\n",
    "    \n",
    "    \n",
    "    del n\n",
    "    \n",
    "# if False:\n",
    "#     tf.reset_default_graph()\n",
    "#     print(tf.train.latest_checkpoint(cur_dir))\n",
    "#     with tf.Session() as sess:\n",
    "#         saver = tf.train.import_meta_graph(cur_dir+'/tf_model-0.meta')\n",
    "#         #print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "\n",
    "#         #saver.restore(sess,  tf.train.latest_checkpoint(savedir+'/basemodel'))\n",
    "#         #print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "#         print( sess.run('decoder_0', feed_dict={'X:0':data['trn_X']}) )\n",
    "#         #mx = sess.run(iblayername+':0', feed_dict={'X:0':Xbatch})\n",
    "#asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the base model, without compression\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tfconfig) as sess:\n",
    "    print(\"Making base model\")\n",
    "    n = Network(input_dim, output_dim)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trainutils.train(sess, mode='ce', beta=0.0, net=n, cfg=cfg, \n",
    "                data=data, savedir=savedir+'/basemodel')\n",
    "    print(\"Model saved in path: %s\" % savedir)\n",
    "    del n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['nlIB', 'VIB']:\n",
    "    for beta in betavals:\n",
    "        if np.isclose(beta, 0):\n",
    "            continue\n",
    "        tf.reset_default_graph()\n",
    "        with tf.Session(config=tfconfig) as sess:\n",
    "            n = Network(input_dim, output_dim)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            tf.train.Saver().restore(sess, tf.train.latest_checkpoint(savedir+'/basemodel'))\n",
    "\n",
    "            sqmode = 'sq'  if cfg['squaredIB'] else 'reg'\n",
    "            runndx = 0\n",
    "            savename = savedir + '/results-%s-%0.5f-%s-run%d' % (mode, beta, sqmode, runndx)\n",
    "            trainutils.train(sess, mode=mode, beta=beta, net=n, cfg=cfg, data=data, savedir=savename,\n",
    "                  optimization_callback=n.iblayerobj.optimize_eta)\n",
    "            print(\"Model saved in path: %s\" % savedir)\n",
    "            del n\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(act[:,0], act[1,:], alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betavals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
