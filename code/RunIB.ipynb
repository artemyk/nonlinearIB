{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import time, os, pickle, pathlib\n",
    "\n",
    "from loaddata import load_mnist, one_hot\n",
    "import model\n",
    "import trainutils\n",
    "\n",
    "report_every = 10  # how often to print stats during training\n",
    "n_runs       = 1   # how many times to repeat the whole scan across beta's\n",
    "savedirbase  = str(pathlib.Path().absolute()) + '/saveddata/'\n",
    "\n",
    "recreate_basemodel = True  # Starting model, with no info-theoretic regularization\n",
    "base_cfg = {\n",
    "    # SGD batch size\n",
    "    'n_batch'         : 128 , \n",
    "    # whether to train noise variance with gradient descent, or other\n",
    "    #  scipy optimizer loop that runs once an epoch\n",
    "    'gradient_train_noisevar' : True, \n",
    "    # if gradient_train_noisevar=False, then size of batch for training noise variance\n",
    "    'n_noisevar_batch': 1000,\n",
    "    # whether to set noisevar to optimal value before training\n",
    "    'initial_fitvar' : False,\n",
    "}\n",
    "\n",
    "\n",
    "# runtype = 'MNIST'\n",
    "runtype = 'NoisyClassifier'\n",
    "#runtype = 'Regression'\n",
    "assert(runtype in ['MNIST', 'NoisyClassifier', 'Regression'])\n",
    "\n",
    "if runtype == 'MNIST':\n",
    "    data = load_mnist()\n",
    "    savedir = runtype + '/v1'\n",
    "    cfg = {\n",
    "        'input_dims'  : 784,\n",
    "        'entropyY'    : np.log(10), \n",
    "        'n_epochs'    : 150,\n",
    "        'squaredIB'   : True,\n",
    "        'encoder_arch': [(512,tf.nn.relu),(512,tf.nn.relu),(2,None)], \n",
    "        'decoder_arch': [(512,tf.nn.relu),(10,None)],\n",
    "        'err_func'    : 'softmax_ce_v2',\n",
    "    }\n",
    "\n",
    "if runtype == 'NoisyClassifier':\n",
    "    savedir = runtype + '/v1'\n",
    "    # Data from artificial dataset used in Schwartz-Ziv and Tishby\n",
    "    d1 = scipy.io.loadmat('data/g1.mat')\n",
    "    d2 = scipy.io.loadmat('data/g2.mat')\n",
    "    data = { 'trn_data' : d1['F'].astype('float32'), 'trn_labels': one_hot(d1['y'].flat),\n",
    "             'tst_data' : d2['F'].astype('float32'), 'tst_labels' : one_hot(d2['y'].flat)}\n",
    "    cfg = {\n",
    "        'input_dims'    : 12,\n",
    "        'entropyY'      : np.log(2),\n",
    "        'n_epochs'      : 150,\n",
    "        'squaredIB'     : False,\n",
    "        'encoder_arch'  : [(20,tf.nn.relu),(20,tf.nn.relu),(2,None)], \n",
    "        'decoder_arch'  : [(20,tf.nn.relu),(2,None)],\n",
    "        'err_func'      : 'softmax_ce_v2',\n",
    "    }\n",
    "    \n",
    "if runtype == 'Regression':\n",
    "    savedir = runtype + '/v5sq-eta'\n",
    "    with open('data/regression.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    labelcov = np.cov(data['trn_labels'].T)\n",
    "    entropyY = 0.5 * np.log(np.linalg.det(2*np.pi*np.exp(1)*labelcov))\n",
    "    cfg = {\n",
    "        'input_dims'       : data['trn_data'].shape[1],\n",
    "        'entropyY'         : entropyY,\n",
    "        'n_epochs'         : 200,\n",
    "        'encoder_arch'     : [(100,tf.nn.relu),(100,tf.nn.relu),(2,None)], \n",
    "        'decoder_arch'     : [(100,tf.nn.relu),(10,None)],\n",
    "        'err_func'         : 'mse',\n",
    "        'squaredIB'        : True,\n",
    "    }\n",
    "\n",
    "savedir = savedirbase + savedir\n",
    "for k, v in base_cfg.items():\n",
    "    if k not in cfg: \n",
    "        cfg[k] = v\n",
    "        \n",
    "if cfg['squaredIB']:\n",
    "    betavals = 10**np.linspace(-3, .5, 10, endpoint=True)\n",
    "else:\n",
    "    betavals = 10**np.linspace(-3, 0., 10, endpoint=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "\n",
    "n = model.Net(input_dims   = cfg['input_dims'],\n",
    "              encoder_arch = cfg['encoder_arch'], \n",
    "              decoder_arch = cfg['decoder_arch'],\n",
    "              err_func     = cfg['err_func'],\n",
    "              entropyY     = cfg['entropyY'],\n",
    "              squaredIB    = cfg['squaredIB'],\n",
    "              gradient_train_noisevar=cfg['gradient_train_noisevar'], \n",
    "              noisevar=0.01, init_beta=0.0)\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making base model\n",
      "\n",
      "epoch: 1 | beta: 0.0000 | noisevar: 0.01 | kw: 0.00403459\n",
      "ce:  0.69 /  0.69 | acc:  0.50 /  0.51 | nlIBloss: -0.00 / -0.01 | VIBloss: -0.00 / -0.01 | \n",
      "Ixt:  2.75 /  2.76 | Ixt_lb:  1.59 /  1.59 | vIxt:  8.53 /  8.53 | Iyt:  0.00 /  0.01 | \n",
      "\n",
      "epoch: 11 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0419104\n",
      "ce:  0.11 /  0.11 | acc:  0.95 /  0.95 | nlIBloss: -0.58 / -0.58 | VIBloss: -0.58 / -0.58 | \n",
      "Ixt:  5.51 /  5.51 | Ixt_lb:  4.24 /  4.24 | vIxt:  14.06 /  14.00 | Iyt:  0.58 /  0.58 | \n",
      "\n",
      "epoch: 21 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0427475\n",
      "ce:  0.06 /  0.07 | acc:  0.98 /  0.97 | nlIBloss: -0.64 / -0.63 | VIBloss: -0.64 / -0.63 | \n",
      "Ixt:  5.70 /  5.70 | Ixt_lb:  4.43 /  4.43 | vIxt:  14.75 /  14.55 | Iyt:  0.64 /  0.63 | \n",
      "\n",
      "epoch: 31 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0439873\n",
      "ce:  0.04 /  0.05 | acc:  0.98 /  0.98 | nlIBloss: -0.65 / -0.65 | VIBloss: -0.65 / -0.65 | \n",
      "Ixt:  5.77 /  5.78 | Ixt_lb:  4.50 /  4.52 | vIxt:  15.04 /  15.29 | Iyt:  0.65 /  0.65 | \n",
      "\n",
      "epoch: 41 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0392703\n",
      "ce:  0.04 /  0.04 | acc:  0.99 /  0.99 | nlIBloss: -0.66 / -0.66 | VIBloss: -0.66 / -0.66 | \n",
      "Ixt:  5.84 /  5.86 | Ixt_lb:  4.58 /  4.60 | vIxt:  16.10 /  16.04 | Iyt:  0.66 /  0.66 | \n",
      "\n",
      "epoch: 51 | beta: 0.0000 | noisevar: 0.01 | kw: 0.046163\n",
      "ce:  0.02 /  0.03 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.66 | VIBloss: -0.67 / -0.66 | \n",
      "Ixt:  5.88 /  5.87 | Ixt_lb:  4.63 /  4.62 | vIxt:  16.06 /  16.06 | Iyt:  0.67 /  0.66 | \n",
      "\n",
      "epoch: 61 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0555412\n",
      "ce:  0.02 /  0.02 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.67 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.93 /  5.93 | Ixt_lb:  4.70 /  4.70 | vIxt:  16.47 /  16.56 | Iyt:  0.67 /  0.67 | \n",
      "\n",
      "epoch: 71 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0451756\n",
      "ce:  0.02 /  0.02 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.67 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.96 /  5.93 | Ixt_lb:  4.70 /  4.68 | vIxt:  16.66 /  16.39 | Iyt:  0.67 /  0.67 | \n",
      "\n",
      "epoch: 81 | beta: 0.0000 | noisevar: 0.01 | kw: 0.046974\n",
      "ce:  0.02 /  0.02 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.68 | VIBloss: -0.67 / -0.68 | \n",
      "Ixt:  6.00 /  5.99 | Ixt_lb:  4.75 /  4.74 | vIxt:  17.40 /  17.13 | Iyt:  0.67 /  0.68 | \n",
      "\n",
      "epoch: 91 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0482472\n",
      "ce:  0.02 /  0.02 | acc:  1.00 /  0.99 | nlIBloss: -0.68 / -0.67 | VIBloss: -0.68 / -0.67 | \n",
      "Ixt:  6.07 /  6.06 | Ixt_lb:  4.82 /  4.81 | vIxt:  17.62 /  18.03 | Iyt:  0.68 /  0.67 | \n",
      "\n",
      "epoch: 101 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0375187\n",
      "ce:  0.01 /  0.02 | acc:  0.99 /  0.99 | nlIBloss: -0.68 / -0.67 | VIBloss: -0.68 / -0.67 | \n",
      "Ixt:  6.06 /  6.04 | Ixt_lb:  4.80 /  4.79 | vIxt:  18.49 /  17.99 | Iyt:  0.68 /  0.67 | \n",
      "\n",
      "epoch: 111 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0721505\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  6.12 /  6.12 | Ixt_lb:  4.91 /  4.91 | vIxt:  18.76 /  18.73 | Iyt:  0.68 /  0.68 | \n",
      "\n",
      "epoch: 121 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0657847\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  0.99 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  6.15 /  6.13 | Ixt_lb:  4.92 /  4.91 | vIxt:  18.92 /  18.93 | Iyt:  0.68 /  0.68 | \n",
      "\n",
      "epoch: 131 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0375862\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  6.09 /  6.10 | Ixt_lb:  4.84 /  4.84 | vIxt:  18.56 /  18.68 | Iyt:  0.68 /  0.68 | \n",
      "\n",
      "epoch: 141 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0503238\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.14 /  6.13 | Ixt_lb:  4.91 /  4.89 | vIxt:  19.79 /  19.42 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 151 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0550801\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.13 /  6.16 | Ixt_lb:  4.91 /  4.92 | vIxt:  19.39 /  19.25 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 161 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0457352\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.13 /  6.14 | Ixt_lb:  4.90 /  4.91 | vIxt:  19.71 /  19.63 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 171 | beta: 0.0000 | noisevar: 0.01 | kw: 0.052857\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.69 | VIBloss: -0.68 / -0.69 | \n",
      "Ixt:  6.17 /  6.15 | Ixt_lb:  4.96 /  4.93 | vIxt:  20.51 /  20.14 | Iyt:  0.68 /  0.69 | \n",
      "\n",
      "epoch: 181 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0549287\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.20 /  6.21 | Ixt_lb:  4.98 /  4.99 | vIxt:  20.40 /  21.06 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 191 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0568923\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.19 /  6.22 | Ixt_lb:  4.98 /  5.00 | vIxt:  20.91 /  21.01 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 201 | beta: 0.0000 | noisevar: 0.01 | kw: 0.046263\n",
      "ce:  0.00 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.19 /  6.18 | Ixt_lb:  4.96 /  4.96 | vIxt:  20.95 /  20.87 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 211 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0459052\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.21 /  6.20 | Ixt_lb:  4.98 /  4.97 | vIxt:  21.43 /  20.95 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 221 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0692764\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.68 | VIBloss: -0.69 / -0.68 | \n",
      "Ixt:  6.25 /  6.24 | Ixt_lb:  5.06 /  5.04 | vIxt:  21.14 /  21.05 | Iyt:  0.69 /  0.68 | \n",
      "\n",
      "epoch: 231 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0501384\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.22 /  6.23 | Ixt_lb:  5.01 /  5.02 | vIxt:  22.00 /  22.00 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 241 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0617487\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.25 /  6.27 | Ixt_lb:  5.06 /  5.07 | vIxt:  22.34 /  22.57 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 251 | beta: 0.0000 | noisevar: 0.01 | kw: 0.071643\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.26 /  6.28 | Ixt_lb:  5.08 /  5.10 | vIxt:  21.86 /  22.60 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 261 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0394485\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.21 /  6.23 | Ixt_lb:  4.99 /  5.01 | vIxt:  21.99 /  22.41 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 271 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0420696\n",
      "ce:  0.00 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.25 /  6.26 | Ixt_lb:  5.03 /  5.04 | vIxt:  23.10 /  23.32 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 281 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0466141\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.30 /  6.27 | Ixt_lb:  5.08 /  5.05 | vIxt:  23.40 /  22.98 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 291 | beta: 0.0000 | noisevar: 0.01 | kw: 0.0394917\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.26 /  6.26 | Ixt_lb:  5.04 /  5.03 | vIxt:  23.65 /  22.95 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 301 | beta: 0.0000 | noisevar: 0.01 | kw: 0.057693\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.69 / -0.69 | \n",
      "Ixt:  6.28 /  6.32 | Ixt_lb:  5.09 /  5.12 | vIxt:  23.66 /  23.50 | Iyt:  0.69 /  0.69 | \n",
      "Model saved in path: /home/artemy/nonlinearIB/code/saveddata/NoisyClassifier/v1/_tf_basemodel\n"
     ]
    }
   ],
   "source": [
    "print(\"Making base model\")\n",
    "cfg2 = cfg.copy()\n",
    "#cfg2['n_epochs'] = 10\n",
    "cfg2['beta'] = 0.0\n",
    "sess.run(tf.global_variables_initializer())\n",
    "trainutils.train(sess, cfg2, data, n, n.ce_loss, report_every, fname=savedir+'/results-base')\n",
    "\n",
    "save_path = saver.save(sess, savedir+'/_tf_basemodel')\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess  = tf.Session()\n",
    "#n = model.Net(encoder_arch=[(512,'relu'),(512,'relu'),(2,'relu')], decoder_arch=[(512,'relu'),],\n",
    "#              trainable_sigma=cfg['train_sigma'], log_sigma2=-2, log_eta2=-20, init_beta=0.0)\n",
    "#loader = tf.train.import_meta_graph(basemodelpath+'.meta')\n",
    "#saver.restore(sess, basemodelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing VIB, beta=0.0010\n",
      "\n",
      "epoch: 1 | beta: 0.0010 | noisevar: 0.01 | kw: 0.0865619\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.35 /  6.31 | Ixt_lb:  5.19 /  5.16 | vIxt:  24.09 /  23.26 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 11 | beta: 0.0010 | noisevar: 0.00966099 | kw: 0.0574751\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.13 /  6.13 | Ixt_lb:  4.96 /  4.97 | vIxt:  20.70 /  20.83 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 21 | beta: 0.0010 | noisevar: 0.00915047 | kw: 0.039965\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.02 /  6.02 | Ixt_lb:  4.84 /  4.85 | vIxt:  19.36 /  19.62 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 31 | beta: 0.0010 | noisevar: 0.00884496 | kw: 0.0250927\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.92 /  5.93 | Ixt_lb:  4.72 /  4.73 | vIxt:  18.52 /  18.65 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 41 | beta: 0.0010 | noisevar: 0.00871627 | kw: 0.0260007\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.85 /  5.84 | Ixt_lb:  4.66 /  4.66 | vIxt:  17.71 /  17.72 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 51 | beta: 0.0010 | noisevar: 0.00861653 | kw: 0.0243683\n",
      "ce:  0.00 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.76 /  5.74 | Ixt_lb:  4.59 /  4.57 | vIxt:  17.30 /  17.25 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 61 | beta: 0.0010 | noisevar: 0.00798971 | kw: 0.0208134\n",
      "ce:  0.02 /  0.01 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.67 | VIBloss: -0.66 / -0.66 | \n",
      "Ixt:  5.70 /  5.69 | Ixt_lb:  4.54 /  4.53 | vIxt:  16.39 /  16.47 | Iyt:  0.67 /  0.68 | \n",
      "\n",
      "epoch: 71 | beta: 0.0010 | noisevar: 0.00758944 | kw: 0.0269006\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.68 | VIBloss: -0.68 / -0.67 | \n",
      "Ixt:  5.73 /  5.73 | Ixt_lb:  4.60 /  4.60 | vIxt:  16.30 /  16.59 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 81 | beta: 0.0010 | noisevar: 0.00772714 | kw: 0.0362621\n",
      "ce:  0.01 /  0.01 | acc:  0.99 /  0.99 | nlIBloss: -0.67 / -0.67 | VIBloss: -0.66 / -0.66 | \n",
      "Ixt:  5.68 /  5.68 | Ixt_lb:  4.60 /  4.60 | vIxt:  15.89 /  15.81 | Iyt:  0.68 /  0.68 | \n",
      "\n",
      "epoch: 91 | beta: 0.0010 | noisevar: 0.00720309 | kw: 0.0213209\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.65 /  5.65 | Ixt_lb:  4.51 /  4.51 | vIxt:  15.52 /  15.71 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 101 | beta: 0.0010 | noisevar: 0.00720794 | kw: 0.0206547\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.58 /  5.60 | Ixt_lb:  4.46 /  4.47 | vIxt:  15.60 /  15.54 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 111 | beta: 0.0010 | noisevar: 0.00729173 | kw: 0.0244052\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.55 /  5.57 | Ixt_lb:  4.45 /  4.46 | vIxt:  15.11 /  15.15 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 121 | beta: 0.0010 | noisevar: 0.00671926 | kw: 0.0162517\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.54 /  5.53 | Ixt_lb:  4.40 /  4.40 | vIxt:  15.13 /  15.06 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 131 | beta: 0.0010 | noisevar: 0.00664146 | kw: 0.0184493\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.54 /  5.52 | Ixt_lb:  4.42 /  4.40 | vIxt:  14.94 /  14.80 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 141 | beta: 0.0010 | noisevar: 0.00658319 | kw: 0.0122215\n",
      "ce:  0.00 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.68 / -0.67 | \n",
      "Ixt:  5.47 /  5.47 | Ixt_lb:  4.31 /  4.31 | vIxt:  14.76 /  14.58 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 151 | beta: 0.0010 | noisevar: 0.00683068 | kw: 0.0166742\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.45 /  5.43 | Ixt_lb:  4.31 /  4.30 | vIxt:  14.42 /  14.19 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 161 | beta: 0.0010 | noisevar: 0.00613556 | kw: 0.0120648\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.44 /  5.46 | Ixt_lb:  4.29 /  4.31 | vIxt:  14.27 /  14.50 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 171 | beta: 0.0010 | noisevar: 0.0064888 | kw: 0.0149305\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.37 /  5.37 | Ixt_lb:  4.24 /  4.25 | vIxt:  13.77 /  13.98 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 181 | beta: 0.0010 | noisevar: 0.00635472 | kw: 0.0187743\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.46 /  5.43 | Ixt_lb:  4.34 /  4.32 | vIxt:  14.12 /  13.98 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 191 | beta: 0.0010 | noisevar: 0.00613283 | kw: 0.0143379\n",
      "ce:  0.01 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.41 /  5.41 | Ixt_lb:  4.27 /  4.27 | vIxt:  13.75 /  13.76 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 201 | beta: 0.0010 | noisevar: 0.00591255 | kw: 0.0177454\n",
      "ce:  0.00 /  0.01 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.48 /  5.49 | Ixt_lb:  4.36 /  4.36 | vIxt:  14.01 /  14.06 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 211 | beta: 0.0010 | noisevar: 0.00583825 | kw: 0.0121146\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.40 /  5.41 | Ixt_lb:  4.24 /  4.26 | vIxt:  13.70 /  13.77 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 221 | beta: 0.0010 | noisevar: 0.00555567 | kw: 0.014981\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.47 /  5.47 | Ixt_lb:  4.33 /  4.32 | vIxt:  13.79 /  13.72 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 231 | beta: 0.0010 | noisevar: 0.00560178 | kw: 0.0139023\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.44 /  5.41 | Ixt_lb:  4.29 /  4.26 | vIxt:  13.63 /  13.46 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 241 | beta: 0.0010 | noisevar: 0.00576192 | kw: 0.0139798\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.38 /  5.36 | Ixt_lb:  4.24 /  4.21 | vIxt:  13.48 /  13.18 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 251 | beta: 0.0010 | noisevar: 0.00571735 | kw: 0.0169826\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.39 /  5.38 | Ixt_lb:  4.26 /  4.25 | vIxt:  13.33 /  13.25 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 261 | beta: 0.0010 | noisevar: 0.00555258 | kw: 0.0156115\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.37 /  5.37 | Ixt_lb:  4.22 /  4.23 | vIxt:  13.04 /  13.12 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 271 | beta: 0.0010 | noisevar: 0.00545786 | kw: 0.0186641\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.41 /  5.40 | Ixt_lb:  4.29 /  4.28 | vIxt:  13.30 /  13.19 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 281 | beta: 0.0010 | noisevar: 0.00547505 | kw: 0.0133743\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.38 /  5.38 | Ixt_lb:  4.21 /  4.21 | vIxt:  13.09 /  13.14 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 291 | beta: 0.0010 | noisevar: 0.00531119 | kw: 0.0119839\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.37 /  5.37 | Ixt_lb:  4.19 /  4.19 | vIxt:  13.05 /  13.04 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 301 | beta: 0.0010 | noisevar: 0.00556396 | kw: 0.0147482\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.68 / -0.68 | \n",
      "Ixt:  5.37 /  5.33 | Ixt_lb:  4.20 /  4.17 | vIxt:  13.06 /  12.93 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "\n",
      "Doing nlIB, beta=0.0010\n",
      "\n",
      "epoch: 1 | beta: 0.0010 | noisevar: 0.01 | kw: 0.0506251\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.27 /  6.30 | Ixt_lb:  5.07 /  5.09 | vIxt:  23.48 /  23.76 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 11 | beta: 0.0010 | noisevar: 0.00917303 | kw: 0.0614242\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.37 /  6.37 | Ixt_lb:  5.19 /  5.19 | vIxt:  24.11 /  24.27 | Iyt:  0.69 /  0.69 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 | beta: 0.0010 | noisevar: 0.00871037 | kw: 0.0359986\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.68 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.35 /  6.34 | Ixt_lb:  5.14 /  5.13 | vIxt:  24.48 /  24.02 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 31 | beta: 0.0010 | noisevar: 0.00801644 | kw: 0.0773905\n",
      "ce:  0.04 /  0.04 | acc:  0.99 /  0.99 | nlIBloss: -0.65 / -0.65 | VIBloss: -0.63 / -0.63 | \n",
      "Ixt:  6.46 /  6.44 | Ixt_lb:  5.31 /  5.30 | vIxt:  23.65 /  23.38 | Iyt:  0.66 /  0.65 | \n",
      "\n",
      "epoch: 41 | beta: 0.0010 | noisevar: 0.00748686 | kw: 0.0443207\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.44 /  6.46 | Ixt_lb:  5.26 /  5.28 | vIxt:  24.11 /  24.81 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 51 | beta: 0.0010 | noisevar: 0.00759476 | kw: 0.0601967\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.44 /  6.46 | Ixt_lb:  5.29 /  5.31 | vIxt:  24.56 /  24.96 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 61 | beta: 0.0010 | noisevar: 0.00726238 | kw: 0.035861\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.39 /  6.41 | Ixt_lb:  5.21 /  5.22 | vIxt:  24.29 /  24.68 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 71 | beta: 0.0010 | noisevar: 0.00693226 | kw: 0.0378646\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.42 /  6.42 | Ixt_lb:  5.25 /  5.25 | vIxt:  24.56 /  24.92 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 81 | beta: 0.0010 | noisevar: 0.00643491 | kw: 0.0397303\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.45 /  6.44 | Ixt_lb:  5.29 /  5.29 | vIxt:  24.34 /  24.27 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 91 | beta: 0.0010 | noisevar: 0.00661623 | kw: 0.0384016\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.41 /  6.40 | Ixt_lb:  5.26 /  5.25 | vIxt:  24.82 /  24.27 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 101 | beta: 0.0010 | noisevar: 0.00665827 | kw: 0.0318886\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.35 /  6.34 | Ixt_lb:  5.19 /  5.19 | vIxt:  24.82 /  24.85 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 111 | beta: 0.0010 | noisevar: 0.00688762 | kw: 0.0300848\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.68 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.27 /  6.28 | Ixt_lb:  5.11 /  5.13 | vIxt:  24.55 /  25.02 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 121 | beta: 0.0010 | noisevar: 0.00672009 | kw: 0.0374077\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.31 /  6.30 | Ixt_lb:  5.18 /  5.19 | vIxt:  24.76 /  25.20 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 131 | beta: 0.0010 | noisevar: 0.00644889 | kw: 0.0265271\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.24 /  6.23 | Ixt_lb:  5.11 /  5.10 | vIxt:  24.87 /  24.76 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 141 | beta: 0.0010 | noisevar: 0.00673891 | kw: 0.0272019\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.17 /  6.15 | Ixt_lb:  5.05 /  5.05 | vIxt:  24.85 /  25.14 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 151 | beta: 0.0010 | noisevar: 0.006845 | kw: 0.0219635\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  6.07 /  6.08 | Ixt_lb:  4.96 /  4.97 | vIxt:  25.11 /  25.01 | Iyt:  0.69 /  0.69 | \n",
      "\n",
      "epoch: 161 | beta: 0.0010 | noisevar: 0.00739799 | kw: 0.0214968\n",
      "ce:  0.00 /  0.00 | acc:  1.00 /  1.00 | nlIBloss: -0.69 / -0.69 | VIBloss: -0.67 / -0.67 | \n",
      "Ixt:  5.94 /  5.93 | Ixt_lb:  4.85 /  4.84 | vIxt:  24.69 /  24.48 | Iyt:  0.69 /  0.69 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-92dfe2f69628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mcfg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_fitvar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nonlinearIB/code/trainutils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(sess, cfg, data, n, loss, report_every, fname, fit_var)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mcparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for runndx in range(n_runs):\n",
    "    for beta in betavals:\n",
    "        if np.isclose(beta,0): \n",
    "            continue\n",
    "        for mode in ['VIB','nlIB',]:\n",
    "            saver.restore(sess, savedir+'/_tf_basemodel')\n",
    "\n",
    "            if mode == 'nlIB':\n",
    "                loss      = n.nlIB_loss\n",
    "            elif mode == 'VIB':\n",
    "                loss      = n.VIB_loss\n",
    "            else:\n",
    "                raise Exception('Unknown mode')\n",
    "\n",
    "            print(\"Doing %s, beta=%0.4f\" % (mode, beta))\n",
    "            fname = savedir+'/results-%s-%0.5f-run%d' % (mode, beta, runndx)\n",
    "            cfg2 = cfg.copy()\n",
    "            cfg2['beta'] = beta\n",
    "            cfg2['mode'] = mode\n",
    "            \n",
    "            trainutils.train(sess, cfg2, data, n, loss, report_every=report_every, fname=fname, fit_var=cfg2['initial_fitvar'])\n",
    "\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot activations\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "x, y = data['tst_data'], data['tst_labels']\n",
    "mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "var = sess.run(n.noisevar)\n",
    "#plt.scatter(mx[:,0],mx[:,1], s=var, c=np.argmax(y,axis=1), alpha=1)\n",
    "ax = plt.axes()\n",
    "for r in mx:\n",
    "    c = plt.Circle((r[0], r[1]), radius=np.sqrt(var), fc='none', alpha=0.05, ec='k')\n",
    "    ax.add_patch(c)\n",
    "plt.axis('scaled');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entropy\n",
    "#mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "\n",
    "d = entropy.pairwise_distance(n.encoder[-1])\n",
    "sess.run(entropy.GMM_entropy(d,1., 2, 'upper'), feed_dict={n.x: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
