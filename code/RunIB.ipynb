{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import time, os, pickle, pathlib\n",
    "\n",
    "import model\n",
    "import trainutils\n",
    "\n",
    "report_every = 10  # how often to print stats during training\n",
    "n_runs       = 1   # how many times to repeat the whole scan across beta's\n",
    "savedirbase  = str(pathlib.Path().absolute()) + '/saveddata3/'\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n",
    "\n",
    "base_cfg = {\n",
    "    'n_batch'         : 128 ,         # SGD batch size\n",
    "    'train_noisevar'  : 'gradient',   # train noise variance with gradient descent ('gradient'), \n",
    "                                      #  scipy optimizer loop ('scipy'), or leave fixed ('none')\n",
    "    'n_noisevar_batch': 1000,         # batch size for training noise variance when train_noisevar='scipy'\n",
    "    'initial_fitvar'  : False,        # whether to set noisevar to optimal value before training\n",
    "    'squaredIB'       : False,        # optimize I(Y;T)-beta*I(X;T) or I(Y;T)-beta*I(X;T)^2 \n",
    "    'err_func'        : 'softmax_ce', # 'softmax_ce' for classification, 'mse' for regression  \n",
    "}\n",
    "\n",
    "\n",
    "runtype = 'MNIST'\n",
    "#runtype = 'NoisyClassifier'\n",
    "# runtype = 'Regression'\n",
    "runtype = 'NoisyClassifierWine'\n",
    "\n",
    "if runtype == 'MNIST':\n",
    "    data = trainutils.load_mnist()\n",
    "    savedir = runtype + '/v1'\n",
    "    cfg = {\n",
    "        'n_epochs'    : 150,\n",
    "        'squaredIB'   : True,\n",
    "        'encoder_arch': [(512,tf.nn.relu),(512,tf.nn.relu),(2,None)], \n",
    "        'decoder_arch': [(512,tf.nn.relu),(10,None)],\n",
    "    }\n",
    "\n",
    "elif runtype == 'NoisyClassifierWine':\n",
    "    data = trainutils.load_wine()\n",
    "    savedir = runtype + '/v10dv5'\n",
    "    cfg = {\n",
    "        'n_epochs'    : 500,\n",
    "        'encoder_arch': [(10,tf.nn.relu),(10,tf.nn.relu),(10,tf.nn.relu),], \n",
    "        #'encoder_arch': [(10,tf.nn.relu),(10,tf.nn.relu),(3,tf.nn.relu),], \n",
    "        'decoder_arch': [(10,tf.nn.relu),(data['trn_Y'].shape[1],None)],\n",
    "    }\n",
    "    \n",
    "elif runtype == 'NoisyClassifier':\n",
    "    savedir = runtype + '/v1'\n",
    "    data = trainutils.load_szt()\n",
    "    cfg = {\n",
    "        'n_epochs'      : 300,\n",
    "        'encoder_arch'  : [(20,tf.nn.relu),(20,tf.nn.relu),(2,None)], \n",
    "        'decoder_arch'  : [(20,tf.nn.relu),(2,None)],\n",
    "    }\n",
    "    \n",
    "elif runtype == 'Regression':\n",
    "    #savedir = runtype + '/v2' # v5sq-eta'\n",
    "    savedir = runtype + '/v10d' # v5sq-eta'\n",
    "    # data generated by makeregressiondata.py\n",
    "    with open('data/regression-100-10.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    labelcov = np.cov(data['trn_Y'].T)\n",
    "    data['entropyY'] = 0.5 * np.log(np.linalg.det(2*np.pi*np.exp(1)*labelcov))\n",
    "    \n",
    "    cfg = {\n",
    "        'n_epochs'         : 500,\n",
    "        #'encoder_arch'     : [(100,tf.nn.relu),(100,tf.nn.relu),(2,None)], \n",
    "        'encoder_arch'     : [(100,tf.nn.relu),(100,tf.nn.relu),(10,None)], \n",
    "        'decoder_arch'     : [(100,tf.nn.relu),(10,None)],\n",
    "        'err_func'         : 'mse',\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    raise Exception('unknown runtype')\n",
    "    \n",
    "savedir = savedirbase + savedir\n",
    "for k, v in base_cfg.items():\n",
    "    if k not in cfg: \n",
    "        cfg[k] = v\n",
    "cfg['optimizer'] = repr(optimizer)\n",
    "\n",
    "#betavals = 10**np.linspace(-5, 0.1, 30, endpoint=True)\n",
    "betavals = 10**np.linspace(0.1, 1, 10, endpoint=True)\n",
    "betavals = np.linspace(0.1, 0.4, 10, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "\n",
    "\n",
    "n = model.Net(input_dims   = data['trn_X'].shape[1],\n",
    "              encoder_arch = cfg['encoder_arch'], \n",
    "              decoder_arch = cfg['decoder_arch'],\n",
    "              err_func     = cfg['err_func'],\n",
    "              entropyY     = data['entropyY'],\n",
    "              trainable_noisevar = cfg['train_noisevar']=='gradient', \n",
    "              noisevar     = 0.01)\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    print(\"Making base model\")\n",
    "    #cfg2['n_epochs'] = 10\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    trainutils.train(sess, 'ce', 0.0, cfg, data, n, optimizer, report_every, fname=savedir+'/results-base')\n",
    "\n",
    "    save_path = saver.save(sess, savedir+'/_tf_basemodel')\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess  = tf.Session()\n",
    "#n = model.Net(encoder_arch=[(512,'relu'),(512,'relu'),(2,'relu')], decoder_arch=[(512,'relu'),],\n",
    "#              trainable_sigma=cfg['train_sigma'], log_sigma2=-2, log_eta2=-20, init_beta=0.0)\n",
    "#loader = tf.train.import_meta_graph(basemodelpath+'.meta')\n",
    "#saver.restore(sess, basemodelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for runndx in range(n_runs):\n",
    "    for beta in betavals:\n",
    "        if np.isclose(beta,0): \n",
    "            continue\n",
    "        for mode in ['VIB','nlIB',]:\n",
    "            saver.restore(sess, savedir+'/_tf_basemodel')\n",
    "            sqmode  = 'sq'  if cfg['squaredIB'] else 'reg'\n",
    "            fname = savedir + '/results-%s-%0.5f-%s-run%d' % (mode, beta, sqmode, runndx)\n",
    "            print(\"Doing %s, beta=%0.4f, %s %s\" % (mode, beta, sqmode, fname))\n",
    "            trainutils.train(sess, mode, beta, cfg, data, n, optimizer, report_every=report_every, fname=fname, fit_var=cfg['initial_fitvar'])\n",
    "\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot activations\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "if False:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    x, y = data['tst_X'], data['tst_Y']\n",
    "    mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "    var = sess.run(n.noisevar)\n",
    "    ax = plt.axes()\n",
    "    for r in mx:\n",
    "        c = plt.Circle((r[0], r[1]), radius=np.sqrt(var), fc='none', alpha=0.05, ec='k')\n",
    "        ax.add_patch(c)\n",
    "    plt.axis('scaled');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
