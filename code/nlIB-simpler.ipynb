{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from loaddata import load_mnist\n",
    "import model\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "data = load_mnist()\n",
    "cfg = {\n",
    "    'n_epochs'    : 150,\n",
    "    'n_sgd'       : 128,\n",
    "    'n_eta_sgd'   : 1000,\n",
    "    'n_sigma_sgd' : 1000,\n",
    "    'beta_epoch'  : 0,\n",
    "    'train_eta'   : False,\n",
    "    'train_sigma' : True,\n",
    "    'encoder_arch': [(512,tf.nn.relu),(512,tf.nn.relu),(2,None)], \n",
    "    'decoder_arch': [(512,tf.nn.relu),],\n",
    "              \n",
    "}\n",
    "report_every = 10\n",
    "make_basemodel = False\n",
    "savedir      = 'outdata/v3.2'\n",
    "basemodelpath = str(Path().absolute()) +\"/basemodel/v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(epoch, data, n, do_print=False):\n",
    "    cur_beta, cur_log_sigma2, cur_log_eta2 = sess.run([n.beta, n.log_sigma2, n.log_eta2])\n",
    "\n",
    "    measures = [n.accuracy, n.nlIB_loss, n.VIB_loss, n.Ixt, n.Ixt_lb, n.vIxt, n.Iyt]\n",
    "    trn_acc, trn_nlIBloss, trn_VIBloss, trn_Ixt, trn_Ixt_lb, trn_vIxt, trn_Iyt = sess.run(measures, feed_dict={n.x: data['train_data'][::10], n.y: data['train_labels'][::10]})\n",
    "    tst_acc, tst_nlIBloss, tst_VIBloss, tst_Ixt, tst_Ixt_lb, tst_vIxt, tst_Iyt = sess.run(measures, feed_dict={n.x: data['test_data'][::10], n.y: data['test_labels'][::10]})\n",
    "\n",
    "    activations_trn = sess.run(n.encoder[-1], feed_dict={n.x: data['train_data'][::10]})\n",
    "    activations_tst = sess.run(n.encoder[-1], feed_dict={n.x: data['test_data']})\n",
    "    cdata = {'epoch': epoch, 'beta': cur_beta, 'log_sigma2': cur_log_sigma2, 'log_eta2': cur_log_eta2,\n",
    "             'trn_acc'     : trn_acc     , 'tst_acc'    : tst_acc, \n",
    "             'trn_nlIBloss': trn_nlIBloss, 'trn_VIBloss': trn_VIBloss,\n",
    "             'tst_nlIBloss': tst_nlIBloss, 'tst_VIBloss': tst_VIBloss,\n",
    "             'trn_Ixt'     : trn_Ixt     , 'trn_Ixt_lb' : trn_Ixt_lb, \n",
    "             'tst_Ixt'     : tst_Ixt     , 'tst_Ixt_lb' : tst_Ixt_lb,\n",
    "             'tst_vIxt'    : tst_vIxt    , 'tst_vIxt'   : tst_vIxt,\n",
    "             'trn_Iyt'     : trn_Iyt     , 'tst_Iyt'    : tst_Iyt,\n",
    "             'activations_trn': activations_trn, 'activations_tst': activations_tst,\n",
    "            }\n",
    "    \n",
    "    if do_print:\n",
    "        print()\n",
    "        print('epoch    : %d | beta: %0.4f | log(noisevar): %0.2f | log(kernelwidth): %0.2f'%\n",
    "              (epoch+1, cur_beta, cur_log_sigma2, cur_log_eta2))\n",
    "        print('acc      : % 0.2f / % 0.2f' % (trn_acc, tst_acc))\n",
    "        print('nlIBloss : % 0.2f / % 0.2f' % (trn_nlIBloss, tst_nlIBloss))\n",
    "        print('VIBloss  : % 0.2f / % 0.2f' % (trn_VIBloss , tst_VIBloss))\n",
    "        print('I(X;T)   : % 0.2f / % 0.2f' % (trn_Ixt, tst_Ixt))\n",
    "        print('I(X;T)lb : % 0.2f / % 0.2f' % (trn_Ixt_lb, tst_Ixt_lb))\n",
    "        print('vI(X;T)  : % 0.2f / % 0.2f' % (trn_vIxt, tst_vIxt))\n",
    "        print('I(Y;T)   : % 0.2f / % 0.2f' % (trn_Iyt, tst_Iyt))\n",
    "        \n",
    "    return cdata\n",
    "\n",
    "\n",
    "def write_data(d, savedir, fname):\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    with open(savedir+'/'+fname, 'wb') as fp:\n",
    "        pickle.dump(d, fp)\n",
    "\n",
    "\n",
    "def train(cfg, data, n, trainstep, beta, report_every, fname):\n",
    "    n_sgd = cfg['n_sgd']\n",
    "    n_mini_batches = int(len(data['train_labels']) / n_sgd)\n",
    "    saved_data = []\n",
    "\n",
    "    for epoch in range(cfg['n_epochs']):\n",
    "        if epoch == cfg['beta_epoch']:\n",
    "            sess.run(n.beta.assign(beta))\n",
    "            #sess.run(n.beta.assign(0.01))\n",
    "            #sess.run(n.allownoise.assign(1.))\n",
    "        #if epoch > beta_epoch:\n",
    "        #    cbeta = cdata['beta'] * 1.1\n",
    "        #    if cbeta > beta:\n",
    "        #        cbeta = beta\n",
    "        #    sess.run(n.beta.assign(cbeta))\n",
    "\n",
    "        \n",
    "        cdata = stats(epoch, data, n, epoch % report_every == 0)\n",
    "        saved_data.append(cdata)\n",
    "        write_data([cfg, saved_data], savedir, fname)\n",
    "\n",
    "        # randomize order of training data\n",
    "        permutation = np.random.permutation(len(data['train_labels']))\n",
    "        train_data = data['train_data'][permutation]\n",
    "        train_labels = data['train_labels'][permutation]\n",
    "\n",
    "#             if n.trainable_sigma:\n",
    "#                 x_batch = train_data[:n_sigma_sgd]\n",
    "#                 y_batch = train_labels[:n_sigma_sgd]\n",
    "#                 n.sigma_optimizer.minimize(sess, feed_dict={n.x: x_batch, n.y: y_batch})\n",
    "\n",
    "#             if train_eta:\n",
    "#                 x_batch = train_data[:n_eta_sgd]\n",
    "#                 n.eta_optimizer.minimize(sess, feed_dict={n.x: x_batch})\n",
    "\n",
    "        for batch in range(n_mini_batches):\n",
    "            # sample mini-batch\n",
    "            x_batch = train_data[batch * n_sgd:(1 + batch) * n_sgd]\n",
    "            y_batch = train_labels[batch * n_sgd:(1 + batch) * n_sgd]\n",
    "\n",
    "            cparams = {n.x: x_batch, n.y: y_batch}\n",
    "            sess.run(trainstep, feed_dict=cparams)\n",
    "\n",
    "    cdata = stats(epoch+1, data, n, do_print=True)\n",
    "    saved_data.append(cdata)\n",
    "    write_data([cfg, saved_data], savedir, fname)\n",
    "\n",
    "    return saved_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess=tf.Session()\n",
    "\n",
    "n = model.Net(encoder_arch=cfg['encoder_arch'], \n",
    "              decoder_arch=cfg['decoder_arch'],\n",
    "              trainable_sigma=cfg['train_sigma'], log_sigma2=-2, log_eta2=-20, init_beta=0.0)\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if make_basemodel or not os.path.exists(basemodelpath+'.meta'):\n",
    "    print(\"Making base model\")\n",
    "    cfg2 = cfg.copy()\n",
    "    cfg2['n_epochs'] = 50\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train(cfg2, data, n, n.no_log_sigma2_trainstep, 0.0, report_every, fname='results-base')\n",
    "\n",
    "    save_path = saver.save(sess, basemodelpath)\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess  = tf.Session()\n",
    "#n = model.Net(encoder_arch=[(512,'relu'),(512,'relu'),(2,'relu')], decoder_arch=[(512,'relu'),],\n",
    "#              trainable_sigma=cfg['train_sigma'], log_sigma2=-2, log_eta2=-20, init_beta=0.0)\n",
    "#loader = tf.train.import_meta_graph(basemodelpath+'.meta')\n",
    "#saver.restore(sess, basemodelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing VIB, 0.0500\n",
      "\n",
      "epoch    : 1 | beta: 0.0500 | log(noisevar): -2.00 | log(kernelwidth): -20.00\n",
      "acc      :  1.00 /  0.97\n",
      "nlIBloss :  1.14 /  0.20\n",
      "VIBloss  :  441943.12 /  470436.53\n",
      "I(X;T)   :  8.28 /  6.82\n",
      "I(X;T)lb :  7.62 /  6.62\n",
      "vI(X;T)  :  2973.03 /  3067.37\n",
      "I(Y;T)   :  2.29 /  2.13\n",
      "\n",
      "epoch    : 11 | beta: 0.0500 | log(noisevar): -1.57 | log(kernelwidth): -20.00\n",
      "acc      :  0.37 /  0.34\n",
      "nlIBloss : -0.66 / -0.61\n",
      "VIBloss  : -0.32 / -0.29\n",
      "I(X;T)   :  1.42 /  1.38\n",
      "I(X;T)lb :  0.82 /  0.79\n",
      "vI(X;T)  :  2.95 /  2.89\n",
      "I(Y;T)   :  0.76 /  0.71\n",
      "\n",
      "epoch    : 21 | beta: 0.0500 | log(noisevar): -0.69 | log(kernelwidth): -20.00\n",
      "acc      :  0.37 /  0.37\n",
      "nlIBloss : -0.66 / -0.64\n",
      "VIBloss  : -0.57 / -0.56\n",
      "I(X;T)   :  1.36 /  1.35\n",
      "I(X;T)lb :  0.72 /  0.70\n",
      "vI(X;T)  :  1.91 /  1.85\n",
      "I(Y;T)   :  0.75 /  0.73\n",
      "\n",
      "epoch    : 31 | beta: 0.0500 | log(noisevar): -0.89 | log(kernelwidth): -20.00\n",
      "acc      :  0.61 /  0.63\n",
      "nlIBloss : -1.01 / -1.03\n",
      "VIBloss  : -0.88 / -0.91\n",
      "I(X;T)   :  2.21 /  2.18\n",
      "I(X;T)lb :  1.26 /  1.22\n",
      "vI(X;T)  :  2.74 /  2.66\n",
      "I(Y;T)   :  1.25 /  1.27\n",
      "\n",
      "epoch    : 41 | beta: 0.0500 | log(noisevar): -0.95 | log(kernelwidth): -20.00\n",
      "acc      :  0.65 /  0.62\n",
      "nlIBloss : -1.12 / -1.09\n",
      "VIBloss  : -0.98 / -0.97\n",
      "I(X;T)   :  2.18 /  2.18\n",
      "I(X;T)lb :  1.26 /  1.24\n",
      "vI(X;T)  :  2.73 /  2.69\n",
      "I(Y;T)   :  1.36 /  1.33\n",
      "\n",
      "epoch    : 51 | beta: 0.0500 | log(noisevar): -0.99 | log(kernelwidth): -20.00\n",
      "acc      :  0.66 /  0.63\n",
      "nlIBloss : -1.18 / -1.14\n",
      "VIBloss  : -1.02 / -0.99\n",
      "I(X;T)   :  2.18 /  2.17\n",
      "I(X;T)lb :  1.29 /  1.27\n",
      "vI(X;T)  :  2.81 /  2.76\n",
      "I(Y;T)   :  1.41 /  1.37\n",
      "\n",
      "epoch    : 61 | beta: 0.0500 | log(noisevar): -1.01 | log(kernelwidth): -20.00\n",
      "acc      :  0.71 /  0.69\n",
      "nlIBloss : -1.28 / -1.24\n",
      "VIBloss  : -1.06 / -1.03\n",
      "I(X;T)   :  2.22 /  2.20\n",
      "I(X;T)lb :  1.38 /  1.36\n",
      "vI(X;T)  :  3.03 /  2.99\n",
      "I(Y;T)   :  1.52 /  1.48\n",
      "\n",
      "epoch    : 71 | beta: 0.0500 | log(noisevar): -1.02 | log(kernelwidth): -20.00\n",
      "acc      :  0.69 /  0.67\n",
      "nlIBloss : -1.26 / -1.22\n",
      "VIBloss  : -1.09 / -1.06\n",
      "I(X;T)   :  2.18 /  2.16\n",
      "I(X;T)lb :  1.31 /  1.29\n",
      "vI(X;T)  :  2.84 /  2.81\n",
      "I(Y;T)   :  1.50 /  1.46\n",
      "\n",
      "epoch    : 81 | beta: 0.0500 | log(noisevar): -1.05 | log(kernelwidth): -20.00\n",
      "acc      :  0.70 /  0.68\n",
      "nlIBloss : -1.32 / -1.26\n",
      "VIBloss  : -1.11 / -1.05\n",
      "I(X;T)   :  2.20 /  2.19\n",
      "I(X;T)lb :  1.37 /  1.35\n",
      "vI(X;T)  :  2.99 /  2.97\n",
      "I(Y;T)   :  1.56 /  1.50\n",
      "\n",
      "epoch    : 91 | beta: 0.0500 | log(noisevar): -1.05 | log(kernelwidth): -20.00\n",
      "acc      :  0.71 /  0.71\n",
      "nlIBloss : -1.32 / -1.25\n",
      "VIBloss  : -1.13 / -1.06\n",
      "I(X;T)   :  2.18 /  2.17\n",
      "I(X;T)lb :  1.35 /  1.33\n",
      "vI(X;T)  :  2.94 /  2.91\n",
      "I(Y;T)   :  1.56 /  1.49\n",
      "\n",
      "epoch    : 101 | beta: 0.0500 | log(noisevar): -1.06 | log(kernelwidth): -20.00\n",
      "acc      :  0.72 /  0.70\n",
      "nlIBloss : -1.33 / -1.28\n",
      "VIBloss  : -1.11 / -1.07\n",
      "I(X;T)   :  2.21 /  2.20\n",
      "I(X;T)lb :  1.39 /  1.37\n",
      "vI(X;T)  :  3.05 /  3.01\n",
      "I(Y;T)   :  1.58 /  1.53\n",
      "\n",
      "epoch    : 111 | beta: 0.0500 | log(noisevar): -1.07 | log(kernelwidth): -20.00\n",
      "acc      :  0.72 /  0.69\n",
      "nlIBloss : -1.37 / -1.27\n",
      "VIBloss  : -1.15 / -1.06\n",
      "I(X;T)   :  2.18 /  2.18\n",
      "I(X;T)lb :  1.39 /  1.36\n",
      "vI(X;T)  :  3.03 /  2.99\n",
      "I(Y;T)   :  1.61 /  1.51\n",
      "\n",
      "epoch    : 121 | beta: 0.0500 | log(noisevar): -1.07 | log(kernelwidth): -20.00\n",
      "acc      :  0.73 /  0.70\n",
      "nlIBloss : -1.37 / -1.30\n",
      "VIBloss  : -1.14 / -1.08\n",
      "I(X;T)   :  2.20 /  2.19\n",
      "I(X;T)lb :  1.41 /  1.38\n",
      "vI(X;T)  :  3.09 /  3.03\n",
      "I(Y;T)   :  1.62 /  1.54\n",
      "\n",
      "epoch    : 131 | beta: 0.0500 | log(noisevar): -1.08 | log(kernelwidth): -20.00\n",
      "acc      :  0.74 /  0.71\n",
      "nlIBloss : -1.43 / -1.33\n",
      "VIBloss  : -1.18 / -1.09\n",
      "I(X;T)   :  2.20 /  2.19\n",
      "I(X;T)lb :  1.43 /  1.41\n",
      "vI(X;T)  :  3.15 /  3.10\n",
      "I(Y;T)   :  1.67 /  1.57\n",
      "\n",
      "epoch    : 141 | beta: 0.0500 | log(noisevar): -1.08 | log(kernelwidth): -20.00\n",
      "acc      :  0.72 /  0.69\n",
      "nlIBloss : -1.36 / -1.28\n",
      "VIBloss  : -1.16 / -1.09\n",
      "I(X;T)   :  2.16 /  2.16\n",
      "I(X;T)lb :  1.36 /  1.33\n",
      "vI(X;T)  :  2.96 /  2.92\n",
      "I(Y;T)   :  1.60 /  1.51\n",
      "\n",
      "epoch    : 151 | beta: 0.0500 | log(noisevar): -1.09 | log(kernelwidth): -20.00\n",
      "acc      :  0.74 /  0.72\n",
      "nlIBloss : -1.43 / -1.29\n",
      "VIBloss  : -1.17 / -1.05\n",
      "I(X;T)   :  2.19 /  2.19\n",
      "I(X;T)lb :  1.43 /  1.40\n",
      "vI(X;T)  :  3.14 /  3.09\n",
      "I(Y;T)   :  1.67 /  1.53\n",
      "\n",
      "\n",
      "Doing nlIB, 0.0500\n",
      "\n",
      "epoch    : 1 | beta: 0.0500 | log(noisevar): -2.00 | log(kernelwidth): -20.00\n",
      "acc      :  1.00 /  0.97\n",
      "nlIBloss :  1.14 /  0.20\n",
      "VIBloss  :  441943.12 /  470436.53\n",
      "I(X;T)   :  8.28 /  6.82\n",
      "I(X;T)lb :  7.62 /  6.62\n",
      "vI(X;T)  :  2973.03 /  3067.37\n",
      "I(Y;T)   :  2.29 /  2.13\n"
     ]
    }
   ],
   "source": [
    "for runndx in range(5):\n",
    "    for beta in np.linspace(0, 1, 21, endpoint=True):\n",
    "        if np.isclose(beta,0): \n",
    "            continue\n",
    "        for mode in ['VIB','nlIB',]:\n",
    "            saver.restore(sess, basemodelpath)\n",
    "\n",
    "            if mode == 'nlIB':\n",
    "                trainstep = n.nlIB_trainstep\n",
    "            elif mode == 'VIB':\n",
    "                trainstep = n.VIB_trainstep\n",
    "            else:\n",
    "                raise Exception('Unknown mode')\n",
    "\n",
    "            print(\"Doing %s, %0.4f\" % (mode, beta))\n",
    "            fname = 'results-%s-%0.5f-run%d' % (mode, beta, runndx)\n",
    "            train(cfg, data, n, trainstep, beta, report_every=report_every, fname=fname)\n",
    "\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "x, y = data['test_data'], data['test_labels']\n",
    "mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "plt.scatter(mx[:,0],mx[:,1], s=4, c=np.argmax(y,axis=1), alpha=0.05)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entropy\n",
    "#mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "\n",
    "d = entropy.pairwise_distance(n.encoder[-1])\n",
    "sess.run(entropy.GMM_entropy(d,1., 2, 'upper'), feed_dict={n.x: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
