{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from loaddata import load_mnist\n",
    "import model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_mnist()\n",
    "tf.reset_default_graph()\n",
    "n_epochs     = 50\n",
    "n_sgd        = 128\n",
    "n_eta_sgd    = 2000\n",
    "#beta         = 0.05\n",
    "beta_epoch   = 10\n",
    "report_every = 10\n",
    "\n",
    "# train model\n",
    "sess=tf.Session()\n",
    "\n",
    "n = model.Net(encoder_arch=[(512,'relu'),(512,'relu'),(2,'relu')], decoder_arch=[(512,'relu'),],\n",
    "              trainable_sigma=False, log_sigma2=-4, init_beta=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing beta=0.00000\n",
      "Doing nlIB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7f743443e3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcur_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_log_sigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_log_eta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_eta2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mtst_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_Ixt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_Iyt\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIyt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mtrn_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_Ixt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_Iyt\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIyt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "for beta in np.linspace(0, 1, 21, endpoint=True):\n",
    "    #with tf.Session() as sess:\n",
    "    print(\"Doing beta=%0.5f\" % beta)\n",
    "    for mode in ('nlIB', 'VIB'):\n",
    "        print(\"Doing %s\" % mode)\n",
    "        trainstep = n.nlIB_trainstep if mode == 'nlIB' else n.VIB_trainstep\n",
    "        loss      = n.nlIB_loss      if mode == 'nlIB' else n.VIB_loss\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        n_mini_batches = int(len(data['train_labels']) / n_sgd)\n",
    "\n",
    "        saved_data = []\n",
    "        fname = 'sqIBv2-%s-%0.5f' % (mode, beta)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            # randomize order of training data\n",
    "            permutation = np.random.permutation(len(data['train_labels']))\n",
    "            train_data = data['train_data'][permutation]\n",
    "            train_labels = data['train_labels'][permutation]\n",
    "\n",
    "            #if epoch == 0:\n",
    "            if n.trainable_sigma:\n",
    "                n.sigma_optimizer.minimize(sess, feed_dict={n.x: x_batch, n.y: y_batch})\n",
    "\n",
    "            x_batch = train_data[:n_eta_sgd]\n",
    "            #y_batch = train_labels[:n_eta_sgd]\n",
    "            n.eta_optimizer.minimize(sess, feed_dict={n.x: x_batch})\n",
    "            if epoch == beta_epoch:\n",
    "                assign_op = n.beta.assign(beta)\n",
    "                sess.run(assign_op)\n",
    "\n",
    "            for batch in range(n_mini_batches):\n",
    "                # sample mini-batch\n",
    "                x_batch = train_data[batch * n_sgd:(1 + batch) * n_sgd]\n",
    "                y_batch = train_labels[batch * n_sgd:(1 + batch) * n_sgd]\n",
    "\n",
    "                cparams = {n.x: x_batch, n.y: y_batch}\n",
    "                sess.run(trainstep, feed_dict=cparams)\n",
    "\n",
    "            cur_beta, cur_log_sigma2, cur_log_eta2 = sess.run([n.beta, n.log_sigma2, n.log_eta2])\n",
    "\n",
    "            tst_acc, tst_loss, tst_Ixt, tst_Iyt = \\\n",
    "                sess.run([n.accuracy, loss, n.Ixt, n.Iyt], feed_dict={n.x: data['test_data'][::10], n.y: data['test_labels'][::10]})\n",
    "            trn_acc, trn_loss, trn_Ixt, trn_Iyt = \\\n",
    "                sess.run([n.accuracy, loss, n.Ixt, n.Iyt], feed_dict={n.x: data['train_data'][::10], n.y: data['train_labels'][::10]})\n",
    "\n",
    "            cdata = {'epoch': epoch, 'beta': cur_beta, 'log_sigma2':cur_log_sigma2, 'log_eta2':cur_log_eta2,\n",
    "                     'trn_acc': trn_acc, 'tst_acc': tst_acc, 'trn_loss': trn_loss, 'tst_loss': tst_loss,\n",
    "                     'trn_Ixt': trn_Ixt, 'tst_Ixt': tst_Ixt, 'trn_Iyt' : trn_Iyt , 'tst_Iyt' : tst_Iyt}\n",
    "            saved_data.append(cdata)\n",
    "\n",
    "            with open('outdata/'+fname, 'wb') as fp:\n",
    "                pickle.dump(saved_data, fp)\n",
    "\n",
    "            if epoch % report_every == 0:\n",
    "                print()\n",
    "                print('epoch  : %d/%d | beta: %0.4f | noisevar: %0.4f | kernelwidth: %0.4f'%\n",
    "                      (epoch+1, n_epochs, cur_beta, np.exp(cur_log_sigma2), np.exp(cur_log_eta2)))\n",
    "                print('acc    : % 0.4f / % 0.4f' % (trn_acc, tst_acc))\n",
    "                print('loss   : % 0.4f / % 0.4f' % (trn_loss, tst_loss))\n",
    "                print('I(X;T) : % 0.4f / % 0.4f' % (trn_Ixt, tst_Ixt))\n",
    "                print('I(Y;T) : % 0.4f / % 0.4f' % (trn_Iyt, tst_Iyt))\n",
    "\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,10))\n",
    "x, y = data['test_data'], data['test_labels']\n",
    "mx = sess.run(n.encoder[-1], feed_dict={n.x: x})\n",
    "plt.scatter(mx[:,0],mx[:,1], s=4, c=np.argmax(y,axis=1), alpha=0.1)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
